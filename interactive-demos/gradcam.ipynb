{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM\n",
    "This example interactively demonstrates Grad-CAM using nnabla's pre-trained model.\n",
    "\n",
    "Grad-CAM : Visual Explanation from Deep Networks via Gradient-based Localization<br>\n",
    "Ramprasaah R. Selvaraju et. al., arXiv (2017) <br>\n",
    "https://arxiv.org/abs/1610.02391"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnabla\n",
    "!git clone https://github.com/sony/nnabla-examples.git\n",
    "%cd nnabla-examples/responsible_ai/gradcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnabla as nn\n",
    "from nnabla.utils.image_utils import imread\n",
    "from nnabla.models.imagenet import VGG16\n",
    "\n",
    "from gradcam import gradcam\n",
    "from gradcam import overlay_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preparation \n",
    "Download image to apply Grad-CAM for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/4/4e/A_crab_spider_on_a_flower_preying_upon_a_euglossine_bee%2C_while_a_butterfly_looks_for_nectar.jpg'\n",
    "img_path = 'input_flower_moth_spider.jpg'\n",
    "if not os.path.isfile(img_path):\n",
    "    tgt = urllib.request.urlopen(url).read()\n",
    "    with open(img_path, mode='wb') as f:\n",
    "        f.write(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what the image looks like.  \n",
    "We can see a flower in the middle on which a butterfly rests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(img_path, size=(224, 224), channel_first=True)\n",
    "plt.imshow(img.transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition\n",
    "Loading the model is very simple.<br>\n",
    "You can choose other models such as `VGG11`, `VGG13`, by specifying the model's name as an argument. Of course, you can choose other pretrained models as well. See the [Docs](https://nnabla.readthedocs.io/en/latest/python/api/models/imagenet.html).\n",
    "\n",
    "**NOTE**: If you use the `VGG16` for the first time, nnabla will automatically download the weights from `https://nnabla.org` and it may take up to a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "x = nn.Variable((batch_size,) + model.input_shape)\n",
    "# set training True since gradient of variable is necessary for Grad-CAM\n",
    "vgg = model(x, training=True, returns_net=True)\n",
    "vgg_variables = vgg.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the input, and extract the necessary outputs.  \n",
    "middle_layer: the last convolution layer  \n",
    "pred: final output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_indices = {\n",
    "    'butterfly': 326,# lycaenid, lycaenid butterfly\n",
    "    'flower': 985,# daisy\n",
    "    'spider': 74,# garden spider\n",
    "}\n",
    "\n",
    "input_name = list(vgg.inputs.keys())[0]\n",
    "vgg_variables[input_name].d = img\n",
    "middle_layer = vgg_variables['VGG16/ReLU_13']\n",
    "pred = vgg_variables[\"VGG16/Affine_3\"]\n",
    "selected = pred[:, target_label_indices['butterfly']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model predicted the image.  \n",
    "We can see the model classified the image as we expect.  \n",
    "Labels regarding butterfly comes high, while flower is also recognized although it is14th ranked probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argsort(-pred.d[0])\n",
    "for i, predicted_label in enumerate(predicted_labels[:15]):\n",
    "        print(f'Top {i+1}, Label index: {predicted_label},  Label name: {model.category_names[predicted_label]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute backward computation to calculate gradient to use for Grad-CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the heatmap using the gradient with respect to the last convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heatmap = gradcam(middle_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Take a look at how the heatmap looks like in the layer of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we overlay the heatmap onto the original image to understand where the model focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = imread(img_path, size=(224, 224))\n",
    "overlaid_img_butterfly = overlay_images(base_img, heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we overlay the heatmap onto the original image to understand where the model focused.  \n",
    "We can speculate the model recognized the butterfly, focusing on its wing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlaid_img_butterfly)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use flower as the label of interest to see how the model see the image this time by calculating Grad-CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset gradient first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in vgg_variables.items():\n",
    "    if 'VGG16/' in k:\n",
    "        v.grad.zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate gradient and Grad-CAM same as for butterfly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_daisy = pred[:, target_label_indices['flower']]\n",
    "selected_daisy.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_daisy = gradcam(middle_layer)\n",
    "plt.matshow(heatmap_daisy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model focus is widely spread comparing to than for butterfly as if the heatmap wrapped the flower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaid_img_daisy = overlay_images(base_img, heatmap_daisy)\n",
    "plt.imshow(overlaid_img_daisy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare images in oneline to enable to see the differences clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {\n",
    "    'original': base_img,\n",
    "    'butterfly': overlaid_img_butterfly,\n",
    "    'flower': overlaid_img_daisy,\n",
    "}\n",
    "\n",
    "\n",
    "row = 1\n",
    "col = len(images)\n",
    "fig, axes = plt.subplots(row, col, figsize=(15,15))\n",
    "\n",
    "for i, (k, v) in enumerate(images.items()):\n",
    "    axes[i].imshow(v)\n",
    "    axes[i].set_title(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
