{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First Order Motion Model\n",
        "![Sample of image animation by first order motion model](https://raw.githubusercontent.com/sony/nnabla-examples/master/GANs/first-order-model/imgs/sample_fake.gif)\n",
        "\n",
        "This example interactively demonstrates [First Order Motion Model](https://papers.nips.cc/paper/2019/file/31c0b36aef265d9221af80872ceb62f9-Paper.pdf), a model for motion transfer which can be used to generate an *image animation*.\n",
        "\n",
        "**This notebook contains a script (record_video) which is distributed under CC BY-SA 4.0 license by [Emily Xie](https://stackoverflow.com/users/2738225/emily-xie) at https://stackoverflow.com/a/62804023, therefore this notebook is also distributed under the same license.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparation\n",
        "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime â†’ change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%cd nnabla-examples/GANs/first-order-model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need the latest PyYAML package to run this example, so we will upgrade that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install --upgrade PyYAML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define a function which plays videos in Colab. Simply run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "\n",
        "def play_video(filename, height=512, width=512):\n",
        "    mp4 = open(filename, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f\"\"\"\n",
        "    <video width={width} height={height} controls>\n",
        "          <source src={data_url} type=\"video/mp4\">\n",
        "    </video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quickstart\n",
        "Now take a look what this model can do! Simply run the following cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python animate.py --source imgs/sample_src.png \\\n",
        "                  --driving imgs/sample_drv.mp4 \\\n",
        "                  --adapt-movement-scale --fps 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "play_video('result/arbitrary/sample_src.png_by_sample_drv.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the model generates an *animation* of source image using the reference motion of driving video.\n",
        "\n",
        "Next, let's try with a different image. Please upload some face image you have. Note that the face **must** have the same pose as the first frame of the driving video, in short, the image must contain frontal face."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload Image\n",
        "Run the following cell to upload your own image. Note that too small images might cause a poor result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "\n",
        "img = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's rename the image for convenience.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "ext = os.path.splitext(list(img.keys())[-1])[-1]\n",
        "os.rename(list(img.keys())[-1], \"input_image{}\".format(ext)) \n",
        "input_img = \"input_image\" + ext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Animation using arbitrary source images\n",
        "\n",
        "Now that you uploaded the image, let's use that for animation. The source image comes to life!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python animate.py --source $input_img \\\n",
        "                  --driving imgs/sample_drv.mp4 \\\n",
        "                  --adapt-movement-scale --fps 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "play_video(f'result/arbitrary/{input_img}_by_sample_drv.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Record Motion Reference Video\n",
        "Now is the time to use your motion! Here you can record a video as motion reference and the model will *animate* the source image just like you do! First of all, define the function which allows Colab to access a camera and record the video with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "\n",
        "def record_video(filename='video.mp4'):\n",
        "\n",
        "    # code from: https://stackoverflow.com/questions/62529304/is-there-any-way-to-capture-live-video-using-webcam-in-google-colab\n",
        "\n",
        "    js = Javascript(\"\"\"\n",
        "        async function recordVideo() {\n",
        "            const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            const stopCapture = document.createElement(\"button\");\n",
        "            capture.textContent = \"Start Recording\";\n",
        "            capture.style.background = \"green\";\n",
        "            capture.style.color = \"white\";\n",
        "\n",
        "            stopCapture.textContent = \"Stop Recording\";\n",
        "            stopCapture.style.background = \"red\";\n",
        "            stopCapture.style.color = \"white\";\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            const recordingVid = document.createElement(\"video\");\n",
        "            video.style.display = 'block';\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: { width: {ideal: 256}, height: {ideal: 256}, facingMode: 'user'}});\n",
        "            let recorder = new MediaRecorder(stream, options);\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            await new Promise((resolve) => {\n",
        "                capture.onclick = resolve;\n",
        "            });\n",
        "            recorder.start();\n",
        "            capture.replaceWith(stopCapture);\n",
        "            await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "            recorder.stop();\n",
        "\n",
        "            let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "            let arrBuff = await recData.data.arrayBuffer();\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "\n",
        "            let binaryString = \"\";\n",
        "            let bytes = new Uint8Array(arrBuff);\n",
        "            bytes.forEach((byte) => {\n",
        "                binaryString += String.fromCharCode(byte);\n",
        "            })\n",
        "            return btoa(binaryString);\n",
        "        }\n",
        "    \"\"\")\n",
        "    try:\n",
        "        display(js)\n",
        "        data = eval_js('recordVideo({})')\n",
        "        binary = b64decode(data)\n",
        "        with open(filename, \"wb\") as video_file:\n",
        "            video_file.write(binary)\n",
        "        print(\"Finished recording video.\")\n",
        "    except Exception as err:\n",
        "        # In case any exceptions arise\n",
        "        print(str(err))\n",
        "    return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cell tries to use a camera on your device. Press \"Start Recording\" and it will start recording! When you press \"Stop Recording\", the recording will stop and the video file will be saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "video_width = 256\n",
        "\n",
        "video_path = record_video()\n",
        "play_video(video_path, height=256, width=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then let's make an animation using your video!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python animate.py --source $input_img \\\n",
        "                  --driving video.mp4 \\\n",
        "                  --adapt-movement-scale --fps 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executing the following cell will show you the result.\n",
        "\n",
        "Note that the animation result strongly depends on the initial pose of source image and driving video, so if the result looks bad, just try with the same pose as the source image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "play_video(f'result/arbitrary/{input_img}_by_video.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
